% Created 2021-09-15 Wed 13:23
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{uocsclub}
\date{\today}
\title{Cool Python Notes\\\medskip
\large Also known as ``Forbidden Knowledge''}
\hypersetup{
 pdfauthor={uocsclub},
 pdftitle={Cool Python Notes},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.2 (Org mode 9.4.4)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

Note that in all of the following, I'm talking about CPython.

Also note that this is going to be presented in the form of a lecture
and none of the material has been reviewed. I think.

\section{Function argument wizardry}
\label{sec:orgf96bee8}
What is the \texttt{*} operator in Python?

It's multiplication.

Hahaha jk it's unpacking of an iterable in a function argument
list. Let's play a koan game.

\begin{verbatim}
>>> def args(*args):
...     return args
\end{verbatim}
This seems like a pretty simple function, but this is not the
case. This function is a looking glass through which we can observe
the functioning of python.

What does the star syntax mean in the argument?

It means to take the arguments passed to the function, put them in a
tuple, and make that tuple be \texttt{args}.
\begin{verbatim}
>>> args(1, 2, 3)
(1, 2, 3)
\end{verbatim}

The \texttt{*} operator isn't only used at function definition time, it has
semantics at function call time too.
\begin{verbatim}
>>> args(*[1, 2, 3])
(1, 2, 3)
\end{verbatim}
In this case, it means to ``unpack'' what it is applied to (it's a
prefix unary operator). It's a prefix (comes before its operand)
unary (it only takes
one operand) operator.

This is pretty cool, but how does it behave when there are other
arguments in play?
\begin{verbatim}
>>> args(1, *[2, 3, 4])
(1, 2, 3, 4)
\end{verbatim}
It seems to unpack each of its elements in place, as if the
structure over which we're iterating did not even exist (and to the
function we're passing this to, it does not).

Let's do some more tests to confirm that this is actually how it works.
\begin{verbatim}
>>> args(1, *[2, 3, 4], 5)
(1, 2, 3, 4, 5)

>>> args(1, *[2, 3, 4], *zip([1, 2, 3], [4,5,6]))
(1, 2, 3, 4, (1, 4), (2, 5), (3, 6))
\end{verbatim}
And indeed, this is what it does.

This \texttt{zip} example merits further examination. What does \texttt{zip} do?
\texttt{zip} takes an arbitrary number of iterable collections, and
iterates over them concurrently, creating tuples with an element
from each collection each iteration. Let's look at an example.
\begin{verbatim}
>>> zip([1,2,3], [4,5,6])
<zip object at 0x7f2d8cdfadc0>
\end{verbatim}
What's this???? a \texttt{<zip object..}? Haha! I've tricked you into
realizing that you can unpack \emph{any generator} with \texttt{*} in argument
lists.
\begin{verbatim}
>>> args(1, *[2, 3, 4], *zip([1, 2, 3], [4,5,6]))
(1, 2, 3, 4, (1, 4), (2, 5), (3, 6))
\end{verbatim}

Let's actually look carefully at what this generator contains:
\begin{verbatim}
>>> list(zip([1,2,3], [4,5,6]))
[(1, 4), (2, 5), (3, 6)]
\end{verbatim}
You can see that it starts with the first element from each
collection, 1 and 4, then the second, 2 and 5, then the third, 3 and 6.

Think you understand argument packing and unpacking? Let's implement
zip.
\begin{verbatim}
def zip1(*args):
    for tup in zip(*args):
        yield tup
\end{verbatim}
Hah! You, in your starry-eyed idealism, expected me to give you a real
example, but I've fooled you once more, instead again showing you
how packing and unpacking are strangely symmetrical. In some sense,
they are opposites. Unpacking goes from a data structure to
arguments, and packing goes from arguments to a data structure. Not
so surprising that they both use the same unary operator, now is it?

Let's go a whole way around the loop:
\begin{verbatim}
def identity_function(*args):
    return tuple(zip(*zip(*args)))

>>> identity_function([1,2,3],[4,5,6])
((1, 2, 3), (4, 5, 6))
\end{verbatim}

I'm not actually going to write zip. If you want to be enlightened
about the limitations of python, go try and write a clean zip
implementation using the features I've just shown you.

Getting back to the matter at hand, I think I saw someone somewhere
using \texttt{**} in an argument list\ldots{}
\begin{verbatim}
>>> args(**list(zip([1,2,3],[4,5,6])))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: __main__.args() argument after ** must be a mapping, not list
\end{verbatim}
Oof. Looks like I need a mapping. 
\begin{verbatim}
>>> args(**{1: 2, 3: 4})
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: keywords must be strings
\end{verbatim}
Oof. Looks like I need strings. Wait, what does it mean by keyword? 
\begin{verbatim}
>>> args(**{'a': 2, 'b': 4})
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: args() got an unexpected keyword argument 'a'
\end{verbatim}
It's taking the dictionary, and passing it as keyword arguments!
We'll get to this later.

Let's make \texttt{args} a bit more interesting, sharpening our looking
glass\ldots{}
\begin{verbatim}
>>> def args(first, second, *rest):
...     print('first', first)
...     print('second', second)
...     print('rest', rest)
\end{verbatim}
We now have another definition of args, one with a combination of
positional args and unpacking.

Using unpacking in this way takes the ``rest'' of the arguments passed
to the function and squashes them into a tuple.
\begin{verbatim}
>>> args(1, 2, 3, 4, 5)
first 1
second 2
rest (3, 4, 5)
\end{verbatim}

Okay, let's combine this with the keyword arg passing through a
dictionary that we had earlier.
\begin{verbatim}
>>> args(**dict(first=0, second=1, rest=(1,2,3,4)))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: args() got an unexpected keyword argument 'rest'
\end{verbatim}
Oops, looks like we can't refer to an unpacking argument in keyword
arguments.
\begin{verbatim}
>>> args(**dict(first=0, second=1))
first 0
second 1
rest ()
\end{verbatim}
Ooh, but we can definitely pass to normal arguments this way. What
about if we try to pass more arguments afterwards to fill in \texttt{rest}?
\begin{verbatim}
>>> args(**dict(first=0, second=1), 'wowza')
  File "<stdin>", line 1
    args(**dict(first=0, second=1), 'wowza')
                                           ^
SyntaxError: positional argument follows keyword argument unpacking
\end{verbatim}
No dice. But, the astute among you might be thinking to
yourselves that this seems a lot like what happens when you try to
pass an argument after a keyword argument.
\begin{verbatim}
>>> args(first=1, second=2, 'wowza')
  File "<stdin>", line 1
    args(first=1, second=2, 'wowza')
                                   ^
SyntaxError: positional argument follows keyword argument
\end{verbatim}
This gives a very very very strong clue about how this is all
implemented under the hood\ldots{}
\begin{verbatim}
>>> args(first=1, second=2)
first 1
second 2
rest ()
>>> args(**{'first':1, 'second':2})
first 1
second 2
rest ()
>>> args(**dict(first=1, second=2))
first 1
second 2
rest ()
\end{verbatim}
What about if we pass an argument before the dictionary?
\begin{verbatim}
>>> args('wowza', **dict(first=0, second=1, third=3))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: args() got multiple values for argument 'first'
>>> args(**dict(first=0, second=1, third=3))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: args() got an unexpected keyword argument 'third'
\end{verbatim}

Okay, now that we're comfortable with unpacking dictionaries, let's
pack them.
\begin{verbatim}
>>> def args(first, second, **rest):
...     print('first', first)
...     print('second', second)
...     print('rest', rest)
\end{verbatim}
Can you guess what the semantics of this will be?
\begin{verbatim}
>>> args(1, 2, 3)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: args() takes 2 positional arguments but 3 were given
>>> args(1, 2, one=1, two=2)
first 1
second 2
rest {'one': 1, 'two': 2}
\end{verbatim}
Okay, this is getting epic. What about if we pass first and second
as keyword arguments?
\begin{verbatim}
>>> args(first=1, second=2)
first 1
second 2
rest {}
>>> args(one=1, two=2, first=1, second=2)
first 1
second 2
rest {'one': 1, 'two': 2}
\end{verbatim}
So you're telling me the order of keyword arguments doesn't matter???

One more thing to blow your mind\ldots{}

\begin{verbatim}
def args(*args, **kwargs):
    print("args", args)
    print("kwargs", kwargs)
\end{verbatim}

You can use both simultaneously. 
\begin{verbatim}
>>> args(1, 2, 3, test=4, five=5)
args (1, 2, 3)
kwargs {'test': 4, 'five': 5}
\end{verbatim}

\section{Food for thought about objects}
\label{sec:orgd3e77b6}
Here's some food for thought\ldots{}

So, you're saying that there's a direct correspondence between
keyword arguments and string-keyed dictionaries\ldots{} And, note the
syntax similarities\ldots{}

Did you know that short strings are interned in Python? This means
that when you use the same string multiple times, you always refer
to the exact same object and comparison and hashing can then be done
by pointer. Python string interning is done with an internal global
dictionary.

Did you know that in Python, the names of functions, variables,
arguments, etc, are all stored as the same kind of string that you
use in the language, and are all interned?

This means that short strings in Python have some extremely valuable
properties. Their equality comparison is constant time. Their
hashing is constant time. Think about what that means for the
implementation of the Python language constructs.

Let's take a look at \texttt{args}.
\begin{verbatim}
>>> args
<function args at 0x7f2d8cc8aca0>
\end{verbatim}
Yes, it's a function, but what is a function?
\begin{verbatim}
>>> dir(args)
['__annotations__', '__call__', '__class__', '__closure__',
 '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__',
 '__doc__', '__eq__', '__format__', '__ge__', '__get__',
 '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__',
 '__init_subclass__', '__kwdefaults__', '__le__', '__lt__',
 '__module__', '__name__', '__ne__', '__new__', '__qualname__',
 '__reduce__', '__reduce_ex__', '__repr__', '__setattr__',
 '__sizeof__', '__str__', '__subclasshook__']
\end{verbatim}
What's this? These are all internal functions which implement \texttt{args}'
functionality.
\begin{verbatim}
>>> args.__call__
<method-wrapper '__call__' of function object at 0x7f2d8cc8aca0>
>>> args.__call__(1, 2)
first 1
second 2
rest ()
\end{verbatim}
Isn't that interesting\ldots{}

What about an object?
\begin{verbatim}
>>> class Thing():
...     pass
... 
>>> Thing()
<__main__.Thing object at 0x7f2d8cecab80>
>>> 
>>> t = Thing()
>>> dir(t)
['__class__', '__delattr__', '__dict__', '__dir__', '__doc__',
 '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__',
 '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__',
 '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__',
 '__repr__', '__setattr__', '__sizeof__', '__str__',
 '__subclasshook__', '__weakref__']
\end{verbatim}
Let's look at the most interesting element here\ldots{}
\begin{verbatim}
>>> t.__dict__
{}
>>> t.__dict__['args'] = args
>>> t.__dict__
{'args': <function args at 0x7f2d8cc8aca0>}
\end{verbatim}
Can you guess what comes next?
\begin{verbatim}
>>> t.args
<function args at 0x7f2d8cc8aca0>
>>> t.args(1, 2, 3, 4, 5)
first 1
second 2
rest (3, 4, 5)
>>> 
\end{verbatim}
What does this tell us about the implementation of Python's object
system?

Can you hear the meta-object programming calling to you? Can you
smell the sweet scent of metaprogramming?

If you don't hear meta-object programming calling to you, please
refer to the following code taken from Peter Norvig's blog:
\begin{verbatim}
class Struct:
    "A structure that can have any fields defined."
    def __init__(self, **entries): self.__dict__.update(entries)

>>> options = Struct(answer=42, linelen=80, font='courier')
>>> options.answer
42
>>> options.answer = 'plastics'
>>> vars(options)
{'answer': 'plastics', 'font': 'courier', 'linelen': 80}
\end{verbatim}

Now, think about what this means for the previous section. How do
you think argument passing is actually implemented under the hood?
How do you think packing and unpacking is done?

\section{Function decorators (AKA functional programming from first principles)}
\label{sec:org07dfb20}
In Python, there exists something very cool called a function
decorator.

It looks like this:
\begin{verbatim}
@function_decorator
def f(something):
    return something
\end{verbatim}

What is it? It's something that can change the way your functions
behave without changing their bodies.

As for how it's actually implemented, it's a function which takes as
its argument another function, and returns a new function. The
original function is then defined as the new function returned by
the decorator.

What's the do-nothing decorator?
\begin{verbatim}
def do_nothing_dec(func):
    return func
\end{verbatim}
And, so, we can decorate a function by putting \texttt{@<decorator-name>}
before the function definition when defining it. It works in the
shell, too.
\begin{verbatim}
@do_nothing_dec
def f():
    return 5

>>> f()
5
\end{verbatim}

Cool. Let's make it even cooler. 
\begin{verbatim}
def add_five(func):
    return lambda: func() + 5
\end{verbatim}
Can you guess what this does to a function it decorates?
\begin{verbatim}
@add_five
def f():
    return 5

>>> f()
10
\end{verbatim}

But wait, I saw somewhere (I can't remember where) that decorators
can take arguments! Let's add that in.
\begin{verbatim}
def add_some(func, num):
    return lambda: func() + num 
\end{verbatim}
And, here we go!
\begin{verbatim}
>>> @add_some(4)
... def f():
...     return 5
... 
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: add_some() missing 1 required positional argument: 'num'
\end{verbatim}

Huh? It didn't work. But, we know that \texttt{add\_some} works as we're
intending, it does return a function which behaves as expected.
\begin{verbatim}
>>> f()
10
>>> add_some(f, 4)
<function add_some.<locals>.<lambda> at 0x7f2d8cc8ae50>
>>> add_some(f, 4)()
14
\end{verbatim}

So, how is this supposed to work? We know that decorators can only
take one argument, the function they're applied to.

How do we pass arguments to a decorator?

(Pause for dramatic effect)

We create a function that returns a decorator.
\begin{verbatim}
def add_some(num):
    def add_other(func):
        return lambda: func() + num 
    return add_other
\end{verbatim}
Note how \texttt{add\_other} refers to \texttt{num}, which is not in its body.
This kind of function (which refers to variables outside of its
body) is called a \textbf{closure} (and is one of the most important things
you could learn, period. The power of closures is incredible.).
\begin{verbatim}
>>> @add_some(5)
... def f():
...     return 3
... 
>>> f()
8
\end{verbatim}
You can read this as \texttt{@(add\_some(5))}. It's evaluating \texttt{add\_some(5)}
before trying to use the result as a decorator.

What can you use it for? Let's say we had some complicated problem
with our recursive program that we couldn't figure out how to
solve. Every time you call it, it loops infinitely!

The boring way to debug that is adding print statements. The \emph{m e t
a} way of doing it is with decorators:
\begin{verbatim}
def trace(func):
    def traced_fun(*args, **kwargs):
        print(f"Call -- {args}, {kwargs}")
        return func(*args, *kwargs)
    return traced_fun
\end{verbatim}
So, let's annotate the function that we couldn't debug.
\begin{verbatim}
>>> @trace
... def f(a):
...     if a == 0:
...             return "you're done!"
...     else:
...             return f(a - 1)
\end{verbatim}
And the veil is removed from your eyes in real time!
\begin{verbatim}
>>> f(-1)
Call -- (-1,), {}
Call -- (-2,), {}
Call -- (-3,), {}
Call -- (-4,), {}
Call -- (-5,), {}
Call -- (-6,), {}
Call -- (-7,), {}
Call -- (-8,), {}
Call -- (-9,), {}
...
...
\end{verbatim}
Aha!
\begin{verbatim}
>>> f(5)
Call -- (5,), {}
Call -- (4,), {}
Call -- (3,), {}
Call -- (2,), {}
Call -- (1,), {}
Call -- (0,), {}
"you're done!"
\end{verbatim}

Alright, so our \emph{m e t a  t r a c e r} seems to work as
expected. But, you know what they say about leaky
abstractions. Sometimes things are not always what they seem.

\begin{verbatim}
>>> f.__name__
'traced_fun'
\end{verbatim}
What is this? \texttt{f}'s name is 'traced-fun'? That can't be right. Let's
cook up some more \emph{m e t a - o b j e c t} goodness.

Let's say we want the \texttt{traced\_fun} we're returning to have some of
the same attributes as the original functon that's passed. Let's
look at \texttt{f}.
\begin{verbatim}
>>> dir(f)
['__annotations__', '__call__', '__class__', '__closure__',
 '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__',
 '__doc__', '__eq__', '__format__', '__ge__', '__get__',
 '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__',
 '__init_subclass__', '__kwdefaults__', '__le__', '__lt__',
 '__module__', '__name__', '__ne__', '__new__', '__qualname__',
 '__reduce__', '__reduce_ex__', '__repr__', '__setattr__',
 '__sizeof__', '__str__', '__subclasshook__']
\end{verbatim}
Looks to me like we'd want \texttt{\_\_module\_\_}, \texttt{\_\_name\_\_}, \texttt{\_\_qualname\_\_},
\texttt{\_\_doc\_\_}, and \texttt{\_\_annotations\_\_} to stay the same after wrapping.

How shall we implement this, I hear you ask? Why, \emph{m e t a - f u n c
t i o n - d e c o r a t o r s}, of course!
\begin{verbatim}
def wraps(wrapped):
    def wrap(wrapper):
        for attr in ('__module__', '__name__', '__qualname__',
                     '__doc__', '__annotations__'):
            try:
                val = getattr(wrapped, attr)
            except AttributeError:
                pass
            else:
                setattr(wrapper, attr, val)
        wrapper.__dict__.update(getattr(wrapped, '__dict__', {}))
        return wrapper

    return wrap
\end{verbatim}

Walking through this, line by line.

\begin{verbatim}
def wraps(wrapped):
\end{verbatim}
we have a function which returns a decorator.
\begin{verbatim}
def wrap(wrapper):
\end{verbatim}
Here's the decorator we're returning. It wraps a wrapper.
\begin{verbatim}
for attr in ('__module__', '__name__', '__qualname__',
             '__doc__', '__annotations__'):
\end{verbatim}
These are all the attributes we want to conserve from the wrapped
function in our new wrapper.
\begin{verbatim}
try:
    val = getattr(wrapped, attr)
\end{verbatim}
Try and get those attributes. If it fails, though:
\begin{verbatim}
except AttributeError:
    pass
\end{verbatim}
We don't set them, because they don't exist.
\begin{verbatim}
else:
    setattr(wrapper, attr, val)
\end{verbatim}
If they do exist, then set the wrapper's attributes to the
corresponding values from the wrapped one.
\begin{verbatim}
wrapper.__dict__.update(getattr(wrapped, '__dict__', {}))
\end{verbatim}
What's more, make sure the new function matches the old one's dict.
\begin{verbatim}
return wrapper
\end{verbatim}
Return our wrapper from the actual decorator.
\begin{verbatim}
return wrap
\end{verbatim}
Return the real decorator.

So, recap on what you just learned. You can write decorators which
decorate decorators which use Python meta-object facilities to
modify functions to remain debuggable after decoration.

And, as a funny example:
\begin{verbatim}
>>> @wraps(f)
... def f2():
...     return 10
... 
>>> f2()
10
>>> f2.__name__
'traced_fun'
\end{verbatim}
Now we know it works.

Also, you think I invented this \texttt{@wraps} thing? No, I stole it from the
\texttt{functools} package. Look for \texttt{update\_wrapper} and \texttt{wraps} in
\texttt{Lib/functools.py} of the \texttt{git@github.com:python/cpython} repository
to see more about it. In general, if you don't understand how
something is implemented, go read the python source code!

Now, let's get the (meta-)meta party started.  Did you think that
decorators only applied to functions? I can't believe you would
think something so un-meta.
\begin{verbatim}
def class_wrapper(class_to_be_wrapped):
    for key, val in vars(class_to_be_wrapped).items():
        if callable(val):
            setattr(class_to_be_wrapped, key, trace(val))
    return class_to_be_wrapped
\end{verbatim}
This decorator applies the \texttt{@trace} decorator to each of the
attributes of \texttt{class\_to\_be\_wrapped} which can be called (implement
the \texttt{callable} interface).
\begin{verbatim}
>>> @class_wrapper
... class TracedClass():
...     def __init__(self, test):
...             self.test = test
...     def some_method(self):
...             return self.test
... 
>>> t = TracedClass("woah there pardner")
Call -- (<__main__.TracedClass object at 0x7f2d8cdcce50>, 'woah there pardner'), {}
>>> t.some_method()
Call -- (<__main__.TracedClass object at 0x7f2d8cdcce50>,), {}
'woah there pardner'
\end{verbatim}

\section{The problem with interpretation}
\label{sec:org4d898dd}
So, we've gathered that the internals of python are implemented
largely using python data structures. What does this tell us?

\begin{itemize}
\item we can do almost nothing in the language without having to lookup
a key in a dictionary, at the very least. A method call involves a
lookup, a function call often involves the consing of various data
structures (especially tuples. Did you know that tuples are stored
on the heap, not the stack? Of course you did, everything is on
the heap). Every single time \texttt{.} is used, a lookup is done in some
dictionary.
\item Because the language semantics are implemented with these data
structures (as opposed to, say, vtables in C++, and similar things
in other similarly object oriented languages), you're never
going to escape a certain slow speed at which you're doing
anything. Most of the best applications for python are thin
wrappers over top of other libraries to get out of the python
speed trap (ML, scientific computing) (and, also to reuse existing
codebases. Isn't it nice that python has this C API that is easy
to program to?).
\end{itemize}

\section{A meta-object application (-> meta-app -> metapp)}
\label{sec:orge8e0d7c}
Let's take advantage of some of these newfangled python features to
write something interesting. 

With the help of a handful of miracles, we're going to write a lisp
interpreter. In particular, we're going to write a Scheme
interpreter. Scheme is a small and simple, but very powerful
language.

Let's talk about some of the components of our interpreter.

\subsection{Data types}
\label{sec:org49b95de}
Scheme uses a handful of data types that we'll need to implement.

\begin{itemize}
\item Booleans (we're going to use \texttt{True} and \texttt{False} for this)
\item Numbers (we're going to hack together python's number system)
\item Characters (we're going to use python single-character strings)
\item Strings (python strings)
\item Symbols (python strings)
\item Pairs and lists (python tuples and lists)
\item Vectors (python lists)
\item Procedures (python object)
\end{itemize}

\subsection{Expressions}
\label{sec:org594a798}
In scheme, most things are \emph{expressions} evaluated to produce a
\emph{value} in some environment. (or more than one value)

There are literal expressions, such as \texttt{\#t}, or any number.

There are also compound expressions, which are composed of a pair
of parenthese around sub-expressions. The first subexpression is an
operation, the rest of the subexpressions are operands.

\subsubsection{Let's be pedantic about expressions for a sec.}
\label{sec:org985e5cf}
When you see a form such as \texttt{(a b c)}, you're seeing an s-exp, or
s-expression, or symbol-expression. These are commonly called
"Forms". Forms are the superset composed of expressions,
definitions, so-called "special forms", etc.

\subsection{Environment and binding}
\label{sec:org2e2a582}
In scheme, there exist variables (gasp) which refer to values. We
can bind variables using a \texttt{let} expression. Those variables are
then bound in that let expression. The variables in the let
expression are local.

\subsection{Definitions}
\label{sec:org8e57047}
It is also possible to define global variables with a
\texttt{define}. \texttt{define} creates what is called a 'top-level'
definition. \texttt{define} forms are \emph{definitions}, not
expressions. They can't appear in the places that a normal variable
can.

\subsection{Procedures}
\label{sec:org4c670fc}
We can implement the procedures as python callable objects, and
have their call be equivalent to the evaluation of the function
body with the arguments bound.

\section{Alright, we have enough to implement a first try at the interpreter.}
\label{sec:org66960dc}
We're going to need some way to parse the forms. Let's split it in
two. First, we're going to split the input into tokens with some
clever python hacks, and then we're going to parse the tokens into a
tree.

We use python's \texttt{split} to actually split the string, which saves us
a metric ton of effort.
\begin{verbatim}
def tokenize(text):
    return text.replace('(', ' ( ')\
               .replace(')', ' ) ')\
               .replace("'", " ' ")\
               .split()
\end{verbatim}

Afterwards, we use a simple recursive thing to turn it into a list
structure.
\begin{verbatim}
def treeify(tokens):
    return treeify_aux(tokens)[1]

# goes from tokens to a python list 
def treeify_aux(tokens, i=0, sublist=False):
    done = False
    acc = []
    while i < len(tokens):
        if tokens[i] == '(':
            i, res = treeify_aux(tokens, i + 1, True)
            acc.append(res)
        elif tokens[i] == ')':
            if not sublist:
                raise Exception(f"unmatched close-paren at token index {i}")
            else:
                return (i + 1, acc)
        else:
            acc.append(sym(tokens[i]))
            i += 1

    if not sublist:
        return (i, acc)
    else:
        raise Exception(f"unbalanced open-paren")

def sym(s):
    try:
        return int(s)
    except ValueError:
        try:
            return float(s)
        except ValueError:
            return s # this is a string
\end{verbatim}

Let's test it out.
\begin{verbatim}
>>> tokenize("(define (F a) (+ a a))")
['(', 'define', '(', 'F', 'a', ')', '(', '+', 'a', 'a', ')', ')']

>>> treeify(tokenize("(define (F a) (+ a a)) (let ((x 2)) (+ x x))"))
[['define', ['F', 'a'], 
            ['+', 'a', 'a']], 
 ['let', [['x', '2']], 
         ['+', 'x', 'x']]]
\end{verbatim}
I added some indentation to the second example to make it a bit
easier to read.

\subsection{What's in an environment?}
\label{sec:org4de6658}
When we have a symbol whose binding we want to access, we first look
at the current lexical scope, then at the set of definitions.

The lexical scope is a linked list of dictionaries, (a stack,
effectively) which represent the bindings that are present in
scope. We start from the top of the stack, and go downwards,
returning the first match we find. 

(define) works by modifying the global scope.

\begin{verbatim}
import operator as op
import math
# an Environment is nothing but a mapping from keys to values which
# has an outer sccope
class Env(dict):
    def __init__(self, init={}, outer=None):
        self.update(init)
        self.outer = outer
        # return the env which contains this key
    def find(self, key):
        return self if (key in self) else\
            (self.outer.find(key) if self.outer else None)

global_env = Env({
    '+': op.add, '-':op.sub, '*':op.mul, '/':op.truediv,
    '>':op.gt, '<':op.lt, '>=':op.ge, '<=':op.le, '=':op.eq,
    'abs':     abs,
    'append':  op.add,
    'apply':   lambda f, args: f(*args),
    'begin':   lambda *x: x[-1],
    'car':     lambda x: x[0],
    'cdr':     lambda x: x[1:],
    'cons':    lambda x,y: [x] + y,
    'eq?':     op.is_,
    'equal?':  op.eq,
    'length':  len,
    'list':    lambda *x: list(x),
    'list?':   lambda x: isinstance(x,list),
    'map':     map,
    'max':     max,
    'min':     min,
    'not':     op.not_,
    'null?':   lambda x: x == [],
    'number?': lambda x: isinstance(x, Number),
    'procedure?': callable,
    'round':   round,
    'symbol?': lambda x: isinstance(x, Symbol),
})
global_env.update(filter(lambda x: x[0].find('__') == -1, vars(math).items()))
\end{verbatim}

Here we define all the most important scheme procedures.

\subsection{What's in a procedure?}
\label{sec:org216c97b}
\begin{verbatim}
class Proc(object):
    def __init__(self, args, body, env, name="lambda"):
        self.args = args
        self.body = body
        self.env = env # This is for closures
        self.__name__ = name
    def __call__(self, *args):
        if len(args) != len(self.args):
            raise Exception("Bad # of arguments passed to ")
        e = Env(dict(zip(self.args, args)), self.env)
        print('body', self.body)
        return [tar(x, e) for x in self.body][-1]
\end{verbatim}
\end{document}